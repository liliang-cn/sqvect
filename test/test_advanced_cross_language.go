package main

import (
	"context"
	"fmt"
	"os"
	"math"

	"github.com/liliang-cn/sqvect"
)

func main() {
	fmt.Println("ğŸ¯ Advanced Chinese-English Cross-Language Matching Tests")
	
	dbPath := "test_advanced_cross_lang.db"
	os.Remove(dbPath)
	defer os.Remove(dbPath)

	store, err := sqvect.New(dbPath, 0)
	if err != nil {
		panic(err)
	}
	defer store.Close()

	ctx := context.Background()
	if err := store.Init(ctx); err != nil {
		panic(err)
	}

	// æµ‹è¯•æ•°æ®é›†ï¼šå“ç‰Œåã€åœ°åã€ä¸“æœ‰åè¯åŒ¹é…
	testDatasets := []struct {
		name     string
		documents []DocumentPair
	}{
		{
			name: "å“ç‰Œåæµ‹è¯• (Brand Names)",
			documents: []DocumentPair{
				{"brand_cn_1", "éŸ³ä¹¦é…’å§æä¾›ç²¾è‡´çš„é¸¡å°¾é…’å’Œèˆ’é€‚çš„ç¯å¢ƒ", "Yinshu Bar offers exquisite cocktails and comfortable atmosphere"},
				{"brand_cn_2", "æ˜Ÿå·´å…‹å’–å•¡åœ¨ä¸­å›½å¸‚åœºè¡¨ç°å‡ºè‰²", "Starbucks Coffee performs excellently in Chinese market"},
				{"brand_cn_3", "éº¦å½“åŠ³å¿«é¤è¿é”éå¸ƒå…¨çƒ", "McDonald's fast food chain spreads globally"},
				{"brand_cn_4", "åä¸ºæŠ€æœ¯å…¬å¸çš„åˆ›æ–°èƒ½åŠ›å¾ˆå¼º", "Huawei Technology Company has strong innovation capabilities"},
				{"brand_cn_5", "å°ç±³æ‰‹æœºåœ¨å¹´è½»äººä¸­å¾ˆå—æ¬¢è¿", "Xiaomi phones are very popular among young people"},
			},
		},
		{
			name: "åœ°åæµ‹è¯• (Place Names)",
			documents: []DocumentPair{
				{"place_cn_1", "åŒ—äº¬æ˜¯ä¸­å›½çš„é¦–éƒ½å’Œæ”¿æ²»ä¸­å¿ƒ", "Beijing is the capital and political center of China"},
				{"place_cn_2", "ä¸Šæµ·æ˜¯ä¸­å›½æœ€å¤§çš„ç»æµä¸­å¿ƒ", "Shanghai is China's largest economic center"},
				{"place_cn_3", "æ·±åœ³æ˜¯ä¸­å›½çš„ç§‘æŠ€åˆ›æ–°ä¹‹éƒ½", "Shenzhen is China's technology and innovation capital"},
				{"place_cn_4", "å¹¿å·æ˜¯åå—åœ°åŒºçš„å•†è´¸ä¸­å¿ƒ", "Guangzhou is the commercial center of South China"},
				{"place_cn_5", "æ­å·ä»¥è¥¿æ¹–ç¾æ™¯è€Œé—»å", "Hangzhou is famous for the beautiful West Lake scenery"},
			},
		},
		{
			name: "è¡Œä¸šæœ¯è¯­æµ‹è¯• (Industry Terms)",
			documents: []DocumentPair{
				{"industry_cn_1", "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•", "Artificial Intelligence technology is rapidly developing"},
				{"industry_cn_2", "åŒºå—é“¾åº”ç”¨å‰æ™¯å¹¿é˜”", "Blockchain applications have broad prospects"},
				{"industry_cn_3", "äº‘è®¡ç®—æœåŠ¡è¶Šæ¥è¶Šé‡è¦", "Cloud computing services are becoming increasingly important"},
				{"industry_cn_4", "å¤§æ•°æ®åˆ†æå¸®åŠ©ä¼ä¸šå†³ç­–", "Big data analysis helps enterprise decision-making"},
				{"industry_cn_5", "ç‰©è”ç½‘è¿æ¥ä¸‡ç‰©äº’è”", "Internet of Things connects everything"},
			},
		},
	}

	fmt.Println("\nğŸ“ Inserting test documents...")
	docCount := 0
	for _, dataset := range testDatasets {
		fmt.Printf("\n--- %s ---\n", dataset.name)
		
		for i, docPair := range dataset.documents {
			// Insert Chinese version
			chineseVec := generateSemanticVector(docPair.chinese, 1024, "zh")
			chineseEmb := &sqvect.Embedding{
				ID:      fmt.Sprintf("%s_zh", docPair.id),
				Vector:  chineseVec,
				Content: docPair.chinese,
				Metadata: map[string]string{
					"lang":     "zh",
					"category": dataset.name,
					"pair_id":  docPair.id,
				},
			}
			
			// Insert English version
			englishVec := generateSemanticVector(docPair.english, 1024, "en")
			englishEmb := &sqvect.Embedding{
				ID:      fmt.Sprintf("%s_en", docPair.id),
				Vector:  englishVec,
				Content: docPair.english,
				Metadata: map[string]string{
					"lang":     "en",
					"category": dataset.name,
					"pair_id":  docPair.id,
				},
			}
			
			if err := store.Upsert(ctx, chineseEmb); err != nil {
				fmt.Printf("âŒ Failed Chinese %d: %v\n", i+1, err)
			} else {
				fmt.Printf("âœ… Chinese %d: %s...\n", i+1, docPair.chinese[:min(25, len(docPair.chinese))])
			}
			
			if err := store.Upsert(ctx, englishEmb); err != nil {
				fmt.Printf("âŒ Failed English %d: %v\n", i+1, err)
			} else {
				fmt.Printf("âœ… English %d: %s...\n", i+1, docPair.english[:min(25, len(docPair.english))])
			}
			
			docCount += 2
		}
	}

	fmt.Printf("\nğŸ“Š Total documents inserted: %d\n", docCount)

	// è·¨è¯­è¨€æµ‹è¯•æŸ¥è¯¢
	crossLanguageTests := []TestQuery{
		// å“ç‰Œåè·¨è¯­è¨€åŒ¹é…
		{"éŸ³ä¹¦é…’å§", "zh", "Should match Yinshu Bar in English", []string{"Yinshu", "Bar", "cocktails"}},
		{"Yinshu Bar", "en", "åº”è¯¥åŒ¹é…ä¸­æ–‡éŸ³ä¹¦é…’å§", []string{"éŸ³ä¹¦", "é…’å§", "é¸¡å°¾é…’"}},
		{"æ˜Ÿå·´å…‹", "zh", "Should match Starbucks", []string{"Starbucks", "Coffee"}},
		{"McDonald's", "en", "åº”è¯¥åŒ¹é…éº¦å½“åŠ³", []string{"éº¦å½“åŠ³", "å¿«é¤"}},
		
		// åœ°åè·¨è¯­è¨€åŒ¹é…  
		{"åŒ—äº¬", "zh", "Should match Beijing", []string{"Beijing", "capital"}},
		{"Shanghai", "en", "åº”è¯¥åŒ¹é…ä¸Šæµ·", []string{"ä¸Šæµ·", "ç»æµ"}},
		{"æ·±åœ³ç§‘æŠ€", "zh", "Should match Shenzhen technology", []string{"Shenzhen", "technology", "innovation"}},
		{"Guangzhou business", "en", "åº”è¯¥åŒ¹é…å¹¿å·å•†è´¸", []string{"å¹¿å·", "å•†è´¸"}},
		
		// æŠ€æœ¯æœ¯è¯­åŒ¹é…
		{"äººå·¥æ™ºèƒ½", "zh", "Should match AI", []string{"Artificial", "Intelligence"}},
		{"Blockchain technology", "en", "åº”è¯¥åŒ¹é…åŒºå—é“¾æŠ€æœ¯", []string{"åŒºå—é“¾", "åº”ç”¨"}},
		{"äº‘è®¡ç®—æœåŠ¡", "zh", "Should match cloud computing", []string{"Cloud", "computing", "services"}},
		{"Big Data", "en", "åº”è¯¥åŒ¹é…å¤§æ•°æ®", []string{"å¤§æ•°æ®", "åˆ†æ"}},
	}

	fmt.Println("\nğŸ” Cross-Language Matching Tests...")
	
	successCount := 0
	for i, test := range crossLanguageTests {
		fmt.Printf("\n--- Test %d ---\n", i+1)
		fmt.Printf("Query: \"%s\" (%s)\n", test.query, test.language)
		fmt.Printf("Expected: %s\n", test.expected)
		
		queryVec := generateSemanticVector(test.query, 1024, test.language)
		
		results, err := store.Search(ctx, queryVec, sqvect.SearchOptions{TopK: 5})
		if err != nil {
			fmt.Printf("âŒ Search failed: %v\n", err)
			continue
		}
		
		fmt.Printf("ğŸ“Š Top Results:\n")
		for j, result := range results[:min(3, len(results))] {
			lang := result.Metadata["lang"]
			category := result.Metadata["category"]
			fmt.Printf("  %d. [%.4f] [%s] [%s] %s\n", 
				j+1, result.Score, lang, category, 
				truncate(result.Content, 45))
		}
		
		// è¯„ä¼°åŒ¹é…è´¨é‡
		if len(results) > 0 && evaluateMatch(results[0], test) {
			fmt.Printf("âœ… Successful cross-language match!\n")
			successCount++
		} else {
			fmt.Printf("âŒ Poor cross-language matching\n")
		}
	}

	// åŒè¯­è¨€åŒ¹é…æµ‹è¯•
	fmt.Println("\nğŸ” Same-Language Matching Tests...")
	
	sameLanguageTests := []TestQuery{
		// ä¸­æ–‡åŒä¹‰è¯æµ‹è¯•
		{"é…’å§å¨±ä¹", "zh", "Should match Chinese bar content", []string{"éŸ³ä¹¦é…’å§", "èˆ’é€‚"}},
		{"å’–å•¡åº—", "zh", "Should match coffee content", []string{"æ˜Ÿå·´å…‹", "å’–å•¡"}},
		{"å¿«é¤è¿é”", "zh", "Should match fast food", []string{"éº¦å½“åŠ³", "å¿«é¤"}},
		
		// è‹±æ–‡åŒä¹‰è¯æµ‹è¯•  
		{"bar entertainment", "en", "Should match bar content", []string{"Yinshu", "cocktails"}},
		{"coffee shop", "en", "Should match coffee content", []string{"Starbucks", "Coffee"}},
		{"fast food chain", "en", "Should match McDonald's", []string{"McDonald's", "fast", "food"}},
	}
	
	sameSuccessCount := 0
	for i, test := range sameLanguageTests {
		fmt.Printf("\n--- Same-Language Test %d ---\n", i+1)
		fmt.Printf("Query: \"%s\" (%s)\n", test.query, test.language)
		
		queryVec := generateSemanticVector(test.query, 1024, test.language)
		
		// åªæœç´¢åŒè¯­è¨€æ–‡æ¡£
		results, err := store.SearchWithFilter(ctx, queryVec, 
			sqvect.SearchOptions{TopK: 3}, 
			map[string]interface{}{"lang": test.language})
		
		if err != nil {
			fmt.Printf("âŒ Search failed: %v\n", err)
			continue
		}
		
		fmt.Printf("ğŸ“Š Same-Language Results:\n")
		for j, result := range results {
			category := result.Metadata["category"]
			fmt.Printf("  %d. [%.4f] [%s] %s\n", 
				j+1, result.Score, category,
				truncate(result.Content, 40))
		}
		
		if len(results) > 0 && evaluateMatch(results[0], test) {
			fmt.Printf("âœ… Good same-language match!\n")
			sameSuccessCount++
		} else {
			fmt.Printf("âŒ Poor same-language matching\n")
		}
	}

	// æ€§èƒ½ç»Ÿè®¡
	fmt.Printf("\nğŸ“ˆ Test Results Summary:\n")
	fmt.Printf("  ğŸ“Š Cross-Language Tests: %d/%d successful (%.1f%%)\n", 
		successCount, len(crossLanguageTests), 
		float64(successCount)/float64(len(crossLanguageTests))*100)
	fmt.Printf("  ğŸ“Š Same-Language Tests: %d/%d successful (%.1f%%)\n", 
		sameSuccessCount, len(sameLanguageTests),
		float64(sameSuccessCount)/float64(len(sameLanguageTests))*100)

	// Database stats
	stats, err := store.Stats(ctx)
	if err == nil {
		fmt.Printf("\nğŸ“Š Database Performance:\n")
		fmt.Printf("  - Documents: %d\n", stats.Count)
		fmt.Printf("  - Dimensions: %d\n", stats.Dimensions)
		fmt.Printf("  - Size: %d bytes\n", stats.Size)
		fmt.Printf("  - Avg bytes/doc: %.1f\n", float64(stats.Size)/float64(stats.Count))
	}

	fmt.Println("\nğŸ¯ Key Findings:")
	if successCount < len(crossLanguageTests)/2 {
		fmt.Println("  âŒ Cross-language matching needs significant improvement")
		fmt.Println("  ğŸ’¡ Recommendation: Implement pinyin-based text similarity")
	} else {
		fmt.Println("  âœ… Cross-language matching shows promising results")
	}
	
	if sameSuccessCount >= len(sameLanguageTests)*3/4 {
		fmt.Println("  âœ… Same-language matching works well")
	} else {
		fmt.Println("  âš ï¸ Same-language matching could be improved")
	}
	
	fmt.Println("  ğŸ“‹ Next steps: Add go-pinyin for Chinese-English phonetic matching")
}

type DocumentPair struct {
	id      string
	chinese string
	english string
}

type TestQuery struct {
	query     string
	language  string
	expected  string
	keywords  []string
}

// æ”¹è¿›çš„è¯­ä¹‰å‘é‡ç”Ÿæˆï¼ˆæ¨¡æ‹Ÿæ›´å¥½çš„åµŒå…¥ï¼‰
func generateSemanticVector(text string, dim int, language string) []float32 {
	vector := make([]float32, dim)
	
	// åŸºç¡€å“ˆå¸Œ
	hash := advancedHash(text)
	
	// è¯­è¨€ç‰¹å¾ç¼–ç 
	langBonus := uint32(0)
	if language == "zh" {
		langBonus = 123456
	} else if language == "en" {
		langBonus = 654321
	}
	
	// è¯­ä¹‰ç‰¹å¾æå–ï¼ˆæ¨¡æ‹Ÿï¼‰
	semanticFeatures := extractSemanticFeatures(text, language)
	
	for i := 0; i < dim; i++ {
		seed := hash + langBonus + semanticFeatures + uint32(i*17+31)
		
		// æ·»åŠ ä¸€äº›"è¯­ä¹‰ç›¸å…³æ€§"
		semantic := float32(0)
		for _, keyword := range getKeywords(text, language) {
			keywordHash := advancedHash(keyword)
			if (keywordHash+uint32(i))%100 < 20 { // 20% æ¦‚ç‡å½±å“
				semantic += float32((keywordHash%100)) / 500.0
			}
		}
		
		vector[i] = float32((seed%2000))/2000.0 - 0.5 + semantic
	}
	
	return normalizeVector(vector)
}

func advancedHash(text string) uint32 {
	hash := uint32(5381)
	for _, c := range text {
		hash = hash*33 + uint32(c)
	}
	return hash
}

func extractSemanticFeatures(text string, language string) uint32 {
	features := uint32(0)
	
	// ç®€å•çš„"è¯­ä¹‰ç‰¹å¾"æå–
	keywords := getKeywords(text, language)
	for _, keyword := range keywords {
		features += advancedHash(keyword) % 10000
	}
	
	return features
}

func getKeywords(text string, language string) []string {
	// è¶…çº§ç®€åŒ–çš„å…³é”®è¯æå–
	if language == "zh" {
		keywords := []string{}
		// ä¸­æ–‡å…³é”®è¯æ¨¡æ‹Ÿ
		chineseKeywords := map[string]bool{
			"é…’å§": true, "å’–å•¡": true, "æŠ€æœ¯": true, "å…¬å¸": true,
			"åŒ—äº¬": true, "ä¸Šæµ·": true, "æ·±åœ³": true, "å¹¿å·": true,
			"äººå·¥æ™ºèƒ½": true, "åŒºå—é“¾": true, "äº‘è®¡ç®—": true,
		}
		for word := range chineseKeywords {
			if contains(text, word) {
				keywords = append(keywords, word)
			}
		}
		return keywords
	} else {
		keywords := []string{}
		englishKeywords := map[string]bool{
			"Bar": true, "Coffee": true, "Technology": true, "Company": true,
			"Beijing": true, "Shanghai": true, "Shenzhen": true, "Guangzhou": true,
			"Intelligence": true, "Blockchain": true, "Cloud": true,
		}
		for word := range englishKeywords {
			if contains(text, word) {
				keywords = append(keywords, word)
			}
		}
		return keywords
	}
}

func evaluateMatch(result sqvect.ScoredEmbedding, test TestQuery) bool {
	// ç®€å•çš„åŒ¹é…è¯„ä¼°
	if result.Score < 0.3 {
		return false
	}
	
	// æ£€æŸ¥æ˜¯å¦åŒ…å«é¢„æœŸå…³é”®è¯
	content := result.Content
	matchCount := 0
	for _, keyword := range test.keywords {
		if contains(content, keyword) {
			matchCount++
		}
	}
	
	return matchCount > 0 || result.Score > 0.6
}

func contains(text, substr string) bool {
	return len(text) >= len(substr) && 
		(text == substr || 
		 len(text) > len(substr) && 
		 (text[:len(substr)] == substr || text[len(text)-len(substr):] == substr ||
		  findInString(text, substr)))
}

func findInString(text, substr string) bool {
	for i := 0; i <= len(text)-len(substr); i++ {
		if text[i:i+len(substr)] == substr {
			return true
		}
	}
	return false
}

func truncate(text string, maxLen int) string {
	if len(text) <= maxLen {
		return text
	}
	return text[:maxLen] + "..."
}

func normalizeVector(vector []float32) []float32 {
	var norm float64
	for _, v := range vector {
		norm += float64(v * v)
	}
	if norm == 0 {
		return vector
	}
	
	norm = math.Sqrt(norm)
	for i := range vector {
		vector[i] = float32(float64(vector[i]) / norm)
	}
	return vector
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}