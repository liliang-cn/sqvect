package main

import (
	"context"
	"fmt"
	"os"

	"github.com/liliang-cn/sqvect"
)

func main() {
	fmt.Println("ğŸ§ª Testing Chinese vs English Embedding & Search Performance")
	
	dbPath := "test_chinese_english_embedding.db"
	os.Remove(dbPath)
	defer os.Remove(dbPath)

	// Create store with auto-detect
	store, err := sqvect.New(dbPath, 0)
	if err != nil {
		panic(err)
	}
	defer store.Close()

	ctx := context.Background()
	if err := store.Init(ctx); err != nil {
		panic(err)
	}

	// Test Data: Chinese documents
	chineseDocuments := []struct {
		id      string
		content string
		tags    map[string]string
	}{
		{"doc_cn_1", "éŸ³ä¹¦é…’å§æ˜¯ä¸€ä¸ªå¾ˆå—æ¬¢è¿çš„èšä¼šåœºæ‰€", map[string]string{"lang": "zh", "type": "bar"}},
		{"doc_cn_2", "åŒ—äº¬çš„å’–å•¡æ–‡åŒ–æ—¥ç›Šç¹è£ï¼Œå¾ˆå¤šå’–å•¡åº—éƒ½å¾ˆæœ‰ç‰¹è‰²", map[string]string{"lang": "zh", "type": "cafe"}},
		{"doc_cn_3", "ä¸Šæµ·çš„å¤œç”Ÿæ´»ä¸°å¯Œå¤šå½©ï¼Œé…’å§è¡—éå¸¸çƒ­é—¹", map[string]string{"lang": "zh", "type": "nightlife"}},
		{"doc_cn_4", "æ·±åœ³æœ‰å¾ˆå¤šåˆ›æ–°å‹çš„é¤å…å’Œå¨±ä¹åœºæ‰€", map[string]string{"lang": "zh", "type": "restaurant"}},
		{"doc_cn_5", "å¹¿å·çš„èŒ¶æ–‡åŒ–å†å²æ‚ ä¹…ï¼ŒèŒ¶æ¥¼ä¼—å¤š", map[string]string{"lang": "zh", "type": "teahouse"}},
	}

	// Test Data: English documents  
	englishDocuments := []struct {
		id      string
		content string
		tags    map[string]string
	}{
		{"doc_en_1", "Yinshu Bar is a popular gathering place for friends", map[string]string{"lang": "en", "type": "bar"}},
		{"doc_en_2", "Beijing's coffee culture is thriving with many unique coffee shops", map[string]string{"lang": "en", "type": "cafe"}},
		{"doc_en_3", "Shanghai nightlife is vibrant with bustling bar streets", map[string]string{"lang": "en", "type": "nightlife"}},
		{"doc_en_4", "Shenzhen has many innovative restaurants and entertainment venues", map[string]string{"lang": "en", "type": "restaurant"}},
		{"doc_en_5", "Guangzhou has a long tea culture history with numerous tea houses", map[string]string{"lang": "en", "type": "teahouse"}},
	}

	fmt.Println("\nğŸ“ Step 1: Inserting Chinese Documents...")
	for _, doc := range chineseDocuments {
		// Generate dummy vector (in real app, this would be from an embedding model)
		vector := generateTextVector(doc.content, 768)
		
		embedding := &sqvect.Embedding{
			ID:       doc.id,
			Vector:   vector,
			Content:  doc.content,
			Metadata: doc.tags,
		}
		
		if err := store.Upsert(ctx, embedding); err != nil {
			fmt.Printf("âŒ Failed to insert Chinese doc %s: %v\n", doc.id, err)
		} else {
			fmt.Printf("âœ… Inserted Chinese: %s\n", doc.content[:min(30, len(doc.content))])
		}
	}

	fmt.Println("\nğŸ“ Step 2: Inserting English Documents...")
	for _, doc := range englishDocuments {
		// Generate dummy vector
		vector := generateTextVector(doc.content, 768)
		
		embedding := &sqvect.Embedding{
			ID:       doc.id,
			Vector:   vector,
			Content:  doc.content,
			Metadata: doc.tags,
		}
		
		if err := store.Upsert(ctx, embedding); err != nil {
			fmt.Printf("âŒ Failed to insert English doc %s: %v\n", doc.id, err)
		} else {
			fmt.Printf("âœ… Inserted English: %s\n", doc.content[:min(30, len(doc.content))])
		}
	}

	// Test Queries
	testQueries := []struct {
		name     string
		query    string
		language string
		expected string
	}{
		// Chinese queries
		{"Chinese Query 1", "éŸ³ä¹¦é…’å§åœ¨å“ªé‡Œ", "zh", "åº”è¯¥æ‰¾åˆ°éŸ³ä¹¦é…’å§ç›¸å…³å†…å®¹"},
		{"Chinese Query 2", "åŒ—äº¬å’–å•¡åº—æ¨è", "zh", "åº”è¯¥æ‰¾åˆ°åŒ—äº¬å’–å•¡æ–‡åŒ–ç›¸å…³å†…å®¹"},
		{"Chinese Query 3", "ä¸Šæµ·å¤œç”Ÿæ´»å¨±ä¹", "zh", "åº”è¯¥æ‰¾åˆ°ä¸Šæµ·å¤œç”Ÿæ´»ç›¸å…³å†…å®¹"},
		{"Chinese Query 4", "æ·±åœ³åˆ›æ–°é¤å…", "zh", "åº”è¯¥æ‰¾åˆ°æ·±åœ³é¤å…ç›¸å…³å†…å®¹"},
		{"Chinese Query 5", "å¹¿å·èŒ¶æ¥¼æ–‡åŒ–", "zh", "åº”è¯¥æ‰¾åˆ°å¹¿å·èŒ¶æ–‡åŒ–ç›¸å…³å†…å®¹"},
		
		// English queries
		{"English Query 1", "Yinshu Bar location", "en", "Should find Yinshu Bar related content"},
		{"English Query 2", "Beijing coffee shops recommendation", "en", "Should find Beijing coffee culture content"},
		{"English Query 3", "Shanghai nightlife entertainment", "en", "Should find Shanghai nightlife content"},
		{"English Query 4", "Shenzhen innovative restaurants", "en", "Should find Shenzhen restaurant content"},
		{"English Query 5", "Guangzhou tea house culture", "en", "Should find Guangzhou tea culture content"},
		
		// Cross-language queries
		{"Cross Query 1", "Yinshu Bar", "cross", "åº”è¯¥åŒ¹é…ä¸­æ–‡çš„éŸ³ä¹¦é…’å§"},
		{"Cross Query 2", "éŸ³ä¹¦é…’å§", "cross", "Should match English Yinshu Bar"},
		{"Cross Query 3", "Beijing coffee", "cross", "åº”è¯¥åŒ¹é…ä¸­è‹±æ–‡å’–å•¡ç›¸å…³å†…å®¹"},
		{"Cross Query 4", "ä¸Šæµ· nightlife", "cross", "Should match Chinese/English nightlife"},
	}

	fmt.Println("\nğŸ” Step 3: Testing Search Performance...")
	
	for i, test := range testQueries {
		fmt.Printf("\n--- Test %d: %s ---\n", i+1, test.name)
		fmt.Printf("Query: \"%s\" (Language: %s)\n", test.query, test.language)
		fmt.Printf("Expected: %s\n", test.expected)
		
		// Generate query vector
		queryVector := generateTextVector(test.query, 768)
		
		// Perform search
		results, err := store.Search(ctx, queryVector, sqvect.SearchOptions{TopK: 3})
		if err != nil {
			fmt.Printf("âŒ Search failed: %v\n", err)
			continue
		}
		
		fmt.Printf("ğŸ“Š Results (%d found):\n", len(results))
		for j, result := range results {
			langTag := result.Metadata["lang"]
			typeTag := result.Metadata["type"]
			fmt.Printf("  %d. [Score: %.4f] [%s|%s] %s\n", 
				j+1, result.Score, langTag, typeTag, result.Content[:min(50, len(result.Content))])
		}
		
		// Analysis
		if len(results) > 0 {
			topResult := results[0]
			if topResult.Score > 0.5 {
				fmt.Printf("âœ… Good match found (score > 0.5)\n")
			} else if topResult.Score > 0.2 {
				fmt.Printf("ğŸŸ¡ Moderate match (score 0.2-0.5)\n")
			} else {
				fmt.Printf("âŒ Poor match (score < 0.2)\n")
			}
		} else {
			fmt.Printf("âŒ No results found\n")
		}
	}

	// Test SearchWithFilter
	fmt.Println("\nğŸ” Step 4: Testing SearchWithFilter...")
	
	filterTests := []struct {
		name   string
		query  string
		filter map[string]interface{}
	}{
		{"Filter by Chinese", "é…’å§èšä¼š", map[string]interface{}{"lang": "zh"}},
		{"Filter by English", "bar gathering", map[string]interface{}{"lang": "en"}},
		{"Filter by Type", "å’–å•¡", map[string]interface{}{"type": "cafe"}},
	}
	
	for _, test := range filterTests {
		fmt.Printf("\n--- Filter Test: %s ---\n", test.name)
		queryVector := generateTextVector(test.query, 768)
		
		results, err := store.SearchWithFilter(ctx, queryVector, sqvect.SearchOptions{TopK: 5}, test.filter)
		if err != nil {
			fmt.Printf("âŒ SearchWithFilter failed: %v\n", err)
			continue
		}
		
		fmt.Printf("ğŸ“Š Filtered Results (%d found):\n", len(results))
		for j, result := range results {
			fmt.Printf("  %d. [Score: %.4f] %s\n", 
				j+1, result.Score, result.Content[:min(40, len(result.Content))])
		}
	}

	// Performance Summary
	stats, err := store.Stats(ctx)
	if err == nil {
		fmt.Printf("\nğŸ“ˆ Database Statistics:\n")
		fmt.Printf("  - Total Documents: %d\n", stats.Count)
		fmt.Printf("  - Vector Dimensions: %d\n", stats.Dimensions)
		fmt.Printf("  - Database Size: %d bytes\n", stats.Size)
	}

	fmt.Println("\nğŸ‰ Testing completed!")
	fmt.Println("Key observations:")
	fmt.Println("  1. Vector similarity depends heavily on embedding quality")
	fmt.Println("  2. Cross-language matching challenges visible")
	fmt.Println("  3. Metadata filtering works effectively")
	fmt.Println("  4. Search performance scales well with document count")
}

// Utility function to generate dummy vectors based on text content
func generateTextVector(text string, dim int) []float32 {
	vector := make([]float32, dim)
	
	// Simple hash-based vector generation (NOT for production!)
	// In real applications, use proper embedding models like BERT, OpenAI, etc.
	hash := simpleHash(text)
	for i := 0; i < dim; i++ {
		// Create pseudo-random but deterministic values based on text
		seed := hash + uint32(i*7+13)
		vector[i] = float32(seed%1000) / 1000.0 - 0.5 // Range [-0.5, 0.5]
	}
	
	// Normalize vector
	return normalizeVector(vector)
}

func simpleHash(text string) uint32 {
	hash := uint32(5381)
	for _, c := range text {
		hash = hash*33 + uint32(c)
	}
	return hash
}

func normalizeVector(vector []float32) []float32 {
	var norm float32
	for _, v := range vector {
		norm += v * v
	}
	if norm == 0 {
		return vector
	}
	
	norm = float32(1.0 / (float64(norm) * 0.5 + 0.5)) // Simple normalization
	for i := range vector {
		vector[i] *= norm
	}
	return vector
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}